{"paragraphs":[{"cues":[{"time":960,"text":"I want you to imagine"},{"time":3000,"text":"walking into a room,"},{"time":5480,"text":"a control room with a bunch of people,"},{"time":7640,"text":"a hundred people, hunched\nover a desk with little dials,"},{"time":11280,"text":"and that that control room"},{"time":13680,"text":"will shape the thoughts and feelings"},{"time":17400,"text":"of a billion people."},{"time":20560,"text":"This might sound like science fiction,"},{"time":23320,"text":"but this actually exists"},{"time":25560,"text":"right now, today."}]},{"cues":[{"time":28040,"text":"I know because I used to be\nin one of those control rooms."},{"time":32159,"text":"I was a design ethicist at Google,"},{"time":34480,"text":"where I studied how do you ethically\nsteer people's thoughts?"},{"time":38560,"text":"Because what we don't talk about\nis how the handful of people"},{"time":41480,"text":"working at a handful\nof technology companies"},{"time":44040,"text":"through their choices will steer\nwhat a billion people are thinking today."},{"time":50400,"text":"Because when you pull out your phone"},{"time":52160,"text":"and they design how this works\nor what's on the feed,"},{"time":55280,"text":"it's scheduling little blocks\nof time in our minds."},{"time":58520,"text":"If you see a notification,\nit schedules you to have thoughts"},{"time":61680,"text":"that maybe you didn't intend to have."},{"time":64400,"text":"If you swipe over that notification,"},{"time":67040,"text":"it schedules you into spending\na little bit of time"},{"time":69445,"text":"getting sucked into something"},{"time":70850,"text":"that maybe you didn't intend\nto get sucked into."},{"time":75320,"text":"When we talk about technology,"},{"time":78040,"text":"we tend to talk about it\nas this blue sky opportunity."},{"time":80760,"text":"It could go any direction."},{"time":83400,"text":"And I want to get serious for a moment"},{"time":85280,"text":"and tell you why it's going\nin a very specific direction."},{"time":88840,"text":"Because it's not evolving randomly."},{"time":92000,"text":"There's a hidden goal\ndriving the direction"},{"time":94040,"text":"of all of the technology we make,"},{"time":96200,"text":"and that goal is the race\nfor our attention."},{"time":100840,"text":"Because every new site --"},{"time":103600,"text":"TED, elections, politicians,"},{"time":106360,"text":"games, even meditation apps --"},{"time":108360,"text":"have to compete for one thing,"},{"time":111160,"text":"which is our attention,"},{"time":112920,"text":"and there's only so much of it."},{"time":116440,"text":"And the best way to get people's attention"},{"time":118880,"text":"is to know how someone's mind works."},{"time":121800,"text":"And there's a whole bunch\nof persuasive techniques"},{"time":124160,"text":"that I learned in college at a lab\ncalled the Persuasive Technology Lab"},{"time":127680,"text":"to get people's attention."}]},{"cues":[{"time":129880,"text":"A simple example is YouTube."},{"time":132000,"text":"YouTube wants to maximize\nhow much time you spend."},{"time":134960,"text":"And so what do they do?"},{"time":136840,"text":"They autoplay the next video."},{"time":139760,"text":"And let's say that works really well."},{"time":141600,"text":"They're getting a little bit\nmore of people's time."},{"time":144040,"text":"Well, if you're Netflix,\nyou look at that and say,"},{"time":146440,"text":"well, that's shrinking my market share,"},{"time":148322,"text":"so I'm going to autoplay the next episode."},{"time":151320,"text":"But then if you're Facebook,"},{"time":152720,"text":"you say, that's shrinking\nall of my market share,"},{"time":155080,"text":"so now I have to autoplay\nall the videos in the newsfeed"},{"time":157760,"text":"before waiting for you to click play."},{"time":160320,"text":"So the internet is not evolving at random."},{"time":164320,"text":"The reason it feels\nlike it's sucking us in the way it is"},{"time":168760,"text":"is because of this race for attention."},{"time":171160,"text":"We know where this is going."},{"time":172600,"text":"Technology is not neutral,"},{"time":175320,"text":"and it becomes this race\nto the bottom of the brain stem"},{"time":178760,"text":"of who can go lower to get it."}]},{"cues":[{"time":181920,"text":"Let me give you an example of Snapchat."},{"time":184280,"text":"If you didn't know,\nSnapchat is the number one way"},{"time":188000,"text":"that teenagers in\nthe United States communicate."},{"time":190280,"text":"So if you're like me, and you use\ntext messages to communicate,"},{"time":194480,"text":"Snapchat is that for teenagers,"},{"time":196280,"text":"and there's, like,\na hundred million of them that use it."},{"time":199000,"text":"And they invented\na feature called Snapstreaks,"},{"time":201240,"text":"which shows the number of days in a row"},{"time":203160,"text":"that two people have\ncommunicated with each other."},{"time":205800,"text":"In other words, what they just did"},{"time":207680,"text":"is they gave two people\nsomething they don't want to lose."},{"time":212000,"text":"Because if you're a teenager,\nand you have 150 days in a row,"},{"time":215480,"text":"you don't want that to go away."},{"time":217480,"text":"And so think of the little blocks of time\nthat that schedules in kids' minds."},{"time":222160,"text":"This isn't theoretical:\nwhen kids go on vacation,"},{"time":224520,"text":"it's been shown they give their passwords\nto up to five other friends"},{"time":227800,"text":"to keep their Snapstreaks going,"},{"time":230040,"text":"even when they can't do it."},{"time":232080,"text":"And they have, like, 30 of these things,"},{"time":234040,"text":"and so they have to get through\ntaking photos of just pictures or walls"},{"time":237440,"text":"or ceilings just to get through their day."},{"time":241200,"text":"So it's not even like\nthey're having real conversations."},{"time":243920,"text":"We have a temptation to think about this"},{"time":245880,"text":"as, oh, they're just using Snapchat"},{"time":248600,"text":"the way we used to\ngossip on the telephone."},{"time":250640,"text":"It's probably OK."},{"time":252480,"text":"Well, what this misses\nis that in the 1970s,"},{"time":254760,"text":"when you were just\ngossiping on the telephone,"},{"time":257399,"text":"there wasn't a hundred engineers\non the other side of the screen"},{"time":260440,"text":"who knew exactly\nhow your psychology worked"},{"time":262520,"text":"and orchestrated you\ninto a double bind with each other."}]},{"cues":[{"time":266440,"text":"Now, if this is making you\nfeel a little bit of outrage,"},{"time":270680,"text":"notice that that thought\njust comes over you."},{"time":273280,"text":"Outrage is a really good way also\nof getting your attention,"},{"time":277880,"text":"because we don't choose outrage."},{"time":279480,"text":"It happens to us."},{"time":280920,"text":"And if you're the Facebook newsfeed,"},{"time":282800,"text":"whether you'd want to or not,"},{"time":284240,"text":"you actually benefit when there's outrage."},{"time":287000,"text":"Because outrage\ndoesn't just schedule a reaction"},{"time":289960,"text":"in emotional time, space, for you."},{"time":293440,"text":"We want to share that outrage\nwith other people."},{"time":295880,"text":"So we want to hit share and say,"},{"time":297480,"text":"\"Can you believe the thing\nthat they said?\""},{"time":300520,"text":"And so outrage works really well\nat getting attention,"},{"time":303920,"text":"such that if Facebook had a choice\nbetween showing you the outrage feed"},{"time":307840,"text":"and a calm newsfeed,"},{"time":310120,"text":"they would want\nto show you the outrage feed,"},{"time":312280,"text":"not because someone\nconsciously chose that,"},{"time":314360,"text":"but because that worked better\nat getting your attention."},{"time":319120,"text":"And the newsfeed control room\nis not accountable to us."},{"time":325040,"text":"It's only accountable\nto maximizing attention."},{"time":327360,"text":"It's also accountable,"},{"time":328600,"text":"because of the business model\nof advertising,"},{"time":331000,"text":"for anybody who can pay the most\nto actually walk into the control room"},{"time":334360,"text":"and say, \"That group over there,"},{"time":335960,"text":"I want to schedule these thoughts\ninto their minds.\""},{"time":339760,"text":"So you can target,"},{"time":342040,"text":"you can precisely target a lie"},{"time":344000,"text":"directly to the people\nwho are most susceptible."},{"time":348080,"text":"And because this is profitable,\nit's only going to get worse."}]},{"cues":[{"time":353040,"text":"So I'm here today"},{"time":356160,"text":"because the costs are so obvious."},{"time":360280,"text":"I don't know a more urgent\nproblem than this,"},{"time":362440,"text":"because this problem\nis underneath all other problems."},{"time":366720,"text":"It's not just taking away our agency"},{"time":369920,"text":"to spend our attention\nand live the lives that we want,"},{"time":373720,"text":"it's changing the way\nthat we have our conversations,"},{"time":377280,"text":"it's changing our democracy,"},{"time":379040,"text":"and it's changing our ability\nto have the conversations"},{"time":381680,"text":"and relationships we want with each other."},{"time":385160,"text":"And it affects everyone,"},{"time":386960,"text":"because a billion people\nhave one of these in their pocket."}]},{"cues":[{"time":393360,"text":"So how do we fix this?"},{"time":397080,"text":"We need to make three radical changes"},{"time":400040,"text":"to technology and to our society."},{"time":403720,"text":"The first is we need to acknowledge\nthat we are persuadable."},{"time":408840,"text":"Once you start understanding"},{"time":410240,"text":"that your mind can be scheduled\ninto having little thoughts"},{"time":413040,"text":"or little blocks of time\nthat you didn't choose,"},{"time":415640,"text":"wouldn't we want to use that understanding"},{"time":417720,"text":"and protect against the way\nthat that happens?"},{"time":420600,"text":"I think we need to see ourselves\nfundamentally in a new way."},{"time":423920,"text":"It's almost like a new period\nof human history,"},{"time":426160,"text":"like the Enlightenment,"},{"time":427400,"text":"but almost a kind of\nself-aware Enlightenment,"},{"time":429640,"text":"that we can be persuaded,"},{"time":432320,"text":"and there might be something\nwe want to protect."},{"time":435400,"text":"The second is we need new models\nand accountability systems"},{"time":440000,"text":"so that as the world gets better\nand more and more persuasive over time --"},{"time":443520,"text":"because it's only going\nto get more persuasive --"},{"time":445880,"text":"that the people in those control rooms"},{"time":447760,"text":"are accountable and transparent\nto what we want."},{"time":450240,"text":"The only form of ethical\npersuasion that exists"},{"time":452960,"text":"is when the goals of the persuader"},{"time":454920,"text":"are aligned with the goals\nof the persuadee."},{"time":457640,"text":"And that involves questioning big things,\nlike the business model of advertising."},{"time":462720,"text":"Lastly,"},{"time":464320,"text":"we need a design renaissance,"},{"time":467080,"text":"because once you have\nthis view of human nature,"},{"time":470160,"text":"that you can steer the timelines\nof a billion people --"},{"time":473160,"text":"just imagine, there's people\nwho have some desire"},{"time":475920,"text":"about what they want to do\nand what they want to be thinking"},{"time":478800,"text":"and what they want to be feeling\nand how they want to be informed,"},{"time":481960,"text":"and we're all just tugged\ninto these other directions."},{"time":484520,"text":"And you have a billion people just tugged\ninto all these different directions."},{"time":488240,"text":"Well, imagine an entire design renaissance"},{"time":490320,"text":"that tried to orchestrate\nthe exact and most empowering"},{"time":493440,"text":"time-well-spent way\nfor those timelines to happen."},{"time":496600,"text":"And that would involve two things:"},{"time":498280,"text":"one would be protecting\nagainst the timelines"},{"time":500440,"text":"that we don't want to be experiencing,"},{"time":502320,"text":"the thoughts that we\nwouldn't want to be happening,"},{"time":504760,"text":"so that when that ding happens,\nnot having the ding that sends us away;"},{"time":508120,"text":"and the second would be empowering us\nto live out the timeline that we want."}]},{"cues":[{"time":511760,"text":"So let me give you a concrete example."},{"time":514280,"text":"Today, let's say your friend\ncancels dinner on you,"},{"time":516760,"text":"and you are feeling a little bit lonely."},{"time":520559,"text":"And so what do you do in that moment?"},{"time":522400,"text":"You open up Facebook."},{"time":524960,"text":"And in that moment,"},{"time":526680,"text":"the designers in the control room\nwant to schedule exactly one thing,"},{"time":530080,"text":"which is to maximize how much time\nyou spend on the screen."},{"time":534640,"text":"Now, instead, imagine if those designers\ncreated a different timeline"},{"time":538560,"text":"that was the easiest way,\nusing all of their data,"},{"time":542080,"text":"to actually help you get out\nwith the people that you care about?"},{"time":545200,"text":"Just think, alleviating\nall loneliness in society,"},{"time":550640,"text":"if that was the timeline that Facebook\nwanted to make possible for people."},{"time":554160,"text":"Or imagine a different conversation."},{"time":555899,"text":"Let's say you wanted to post\nsomething supercontroversial on Facebook,"},{"time":559240,"text":"which is a really important\nthing to be able to do,"},{"time":561680,"text":"to talk about controversial topics."},{"time":563400,"text":"And right now, when there's\nthat big comment box,"},{"time":565760,"text":"it's almost asking you,\nwhat key do you want to type?"},{"time":569160,"text":"In other words, it's scheduling\na little timeline of things"},{"time":572000,"text":"you're going to continue\nto do on the screen."},{"time":574160,"text":"And imagine instead that there was\nanother button there saying,"},{"time":577160,"text":"what would be most\ntime well spent for you?"},{"time":579240,"text":"And you click \"host a dinner.\""},{"time":580840,"text":"And right there\nunderneath the item it said,"},{"time":582960,"text":"\"Who wants to RSVP for the dinner?\""},{"time":584680,"text":"And so you'd still have a conversation\nabout something controversial,"},{"time":587960,"text":"but you'd be having it in the most\nempowering place on your timeline,"},{"time":591720,"text":"which would be at home that night\nwith a bunch of a friends over"},{"time":594760,"text":"to talk about it."},{"time":597000,"text":"So imagine we're running, like,\na find and replace"},{"time":601000,"text":"on all of the timelines\nthat are currently steering us"},{"time":603600,"text":"towards more and more\nscreen time persuasively"},{"time":607080,"text":"and replacing all of those timelines"},{"time":609640,"text":"with what do we want in our lives."}]},{"cues":[{"time":614960,"text":"It doesn't have to be this way."},{"time":618360,"text":"Instead of handicapping our attention,"},{"time":620640,"text":"imagine if we used all of this data\nand all of this power"},{"time":623480,"text":"and this new view of human nature"},{"time":625120,"text":"to give us a superhuman ability to focus"},{"time":628000,"text":"and a superhuman ability to put\nour attention to what we cared about"},{"time":632160,"text":"and a superhuman ability\nto have the conversations"},{"time":634800,"text":"that we need to have for democracy."},{"time":639600,"text":"The most complex challenges in the world"},{"time":644280,"text":"require not just us\nto use our attention individually."},{"time":648440,"text":"They require us to use our attention\nand coordinate it together."},{"time":652440,"text":"Climate change is going to require\nthat a lot of people"},{"time":655280,"text":"are being able\nto coordinate their attention"},{"time":657400,"text":"in the most empowering way together."},{"time":659320,"text":"And imagine creating\na superhuman ability to do that."}]},{"cues":[{"time":667000,"text":"Sometimes the world's\nmost pressing and important problems"},{"time":672040,"text":"are not these hypothetical future things\nthat we could create in the future."},{"time":676560,"text":"Sometimes the most pressing problems"},{"time":678320,"text":"are the ones that are\nright underneath our noses,"},{"time":680680,"text":"the things that are already directing\na billion people's thoughts."},{"time":684600,"text":"And maybe instead of getting excited\nabout the new augmented reality"},{"time":688000,"text":"and virtual reality\nand these cool things that could happen,"},{"time":691320,"text":"which are going to be susceptible\nto the same race for attention,"},{"time":694640,"text":"if we could fix the race for attention"},{"time":696840,"text":"on the thing that's already\nin a billion people's pockets."},{"time":700040,"text":"Maybe instead of getting excited"},{"time":701640,"text":"about the most exciting\nnew cool fancy education apps,"},{"time":705840,"text":"we could fix the way\nkids' minds are getting manipulated"},{"time":708760,"text":"into sending empty messages\nback and forth."}]},{"cues":[{"time":712040,"text":"(Applause)"}]},{"cues":[{"time":716360,"text":"Maybe instead of worrying"},{"time":717640,"text":"about hypothetical future\nrunaway artificial intelligences"},{"time":721440,"text":"that are maximizing for one goal,"},{"time":724680,"text":"we could solve the runaway\nartificial intelligence"},{"time":727360,"text":"that already exists right now,"},{"time":729440,"text":"which are these newsfeeds\nmaximizing for one thing."},{"time":734080,"text":"It's almost like instead of running away\nto colonize new planets,"},{"time":737920,"text":"we could fix the one\nthat we're already on."}]},{"cues":[{"time":740000,"text":"(Applause)"}]},{"cues":[{"time":748040,"text":"Solving this problem"},{"time":749840,"text":"is critical infrastructure\nfor solving every other problem."},{"time":754600,"text":"There's nothing in your life\nor in our collective problems"},{"time":758640,"text":"that does not require our ability\nto put our attention where we care about."},{"time":763800,"text":"At the end of our lives,"},{"time":766240,"text":"all we have is our attention and our time."},{"time":769800,"text":"What will be time well spent for ours?"}]},{"cues":[{"time":771720,"text":"Thank you."}]},{"cues":[{"time":772960,"text":"(Applause)"}]},{"cues":[{"time":785760,"text":"Chris Anderson: Tristan, thank you.\nHey, stay up here a sec."},{"time":788720,"text":"First of all, thank you."},{"time":790080,"text":"I know we asked you to do this talk\non pretty short notice,"},{"time":792880,"text":"and you've had quite a stressful week"},{"time":795120,"text":"getting this thing together, so thank you."},{"time":798680,"text":"Some people listening might say,\nwhat you complain about is addiction,"},{"time":802680,"text":"and all these people doing this stuff,\nfor them it's actually interesting."},{"time":806200,"text":"All these design decisions"},{"time":807480,"text":"have built user content\nthat is fantastically interesting."},{"time":810600,"text":"The world's more interesting\nthan it ever has been."},{"time":813040,"text":"What's wrong with that?"}]},{"cues":[{"time":814320,"text":"Tristan Harris:\nI think it's really interesting."},{"time":816600,"text":"One way to see this\nis if you're just YouTube, for example,"},{"time":820640,"text":"you want to always show\nthe more interesting next video."},{"time":823320,"text":"You want to get better and better\nat suggesting that next video,"},{"time":826360,"text":"but even if you could propose\nthe perfect next video"},{"time":828840,"text":"that everyone would want to watch,"},{"time":830520,"text":"it would just be better and better\nat keeping you hooked on the screen."},{"time":833880,"text":"So what's missing in that equation"},{"time":835560,"text":"is figuring out what\nour boundaries would be."},{"time":837720,"text":"You would want YouTube to know\nsomething about, say, falling asleep."},{"time":840960,"text":"The CEO of Netflix recently said,"},{"time":842600,"text":"\"our biggest competitors\nare Facebook, YouTube and sleep.\""},{"time":845360,"text":"And so what we need to recognize\nis that the human architecture is limited"},{"time":849840,"text":"and that we have certain boundaries\nor dimensions of our lives"},{"time":852840,"text":"that we want to be honored and respected,"},{"time":854840,"text":"and technology could help do that."}]},{"cues":[{"time":856680,"text":"(Applause)"}]},{"cues":[{"time":859320,"text":"CA: I mean, could you make the case"},{"time":861040,"text":"that part of the problem here is that\nwe've got a na√Øve model of human nature?"},{"time":867120,"text":"So much of this is justified\nin terms of human preference,"},{"time":869880,"text":"where we've got these algorithms\nthat do an amazing job"},{"time":872520,"text":"of optimizing for human preference,"},{"time":874240,"text":"but which preference?"},{"time":875600,"text":"There's the preferences\nof things that we really care about"},{"time":879120,"text":"when we think about them"},{"time":880520,"text":"versus the preferences\nof what we just instinctively click on."},{"time":883600,"text":"If we could implant that more nuanced\nview of human nature in every design,"},{"time":888280,"text":"would that be a step forward?"}]},{"cues":[{"time":889760,"text":"TH: Absolutely. I mean, I think right now"},{"time":891760,"text":"it's as if all of our technology\nis basically only asking our lizard brain"},{"time":895280,"text":"what's the best way\nto just impulsively get you to do"},{"time":897800,"text":"the next tiniest thing with your time,"},{"time":899960,"text":"instead of asking you in your life"},{"time":901640,"text":"what we would be most\ntime well spent for you?"},{"time":903840,"text":"What would be the perfect timeline\nthat might include something later,"},{"time":907160,"text":"would be time well spent for you\nhere at TED in your last day here?"}]},{"cues":[{"time":910360,"text":"CA: So if Facebook and Google\nand everyone said to us first up,"},{"time":913360,"text":"\"Hey, would you like us\nto optimize for your reflective brain"},{"time":916280,"text":"or your lizard brain? You choose.\""}]},{"cues":[{"time":917960,"text":"TH: Right. That would be one way. Yes."}]},{"cues":[{"time":922358,"text":"CA: You said persuadability,\nthat's an interesting word to me"},{"time":925240,"text":"because to me there's\ntwo different types of persuadability."},{"time":928120,"text":"There's the persuadability\nthat we're trying right now"},{"time":930680,"text":"of reason and thinking\nand making an argument,"},{"time":932880,"text":"but I think you're almost\ntalking about a different kind,"},{"time":935590,"text":"a more visceral type of persuadability,"},{"time":937520,"text":"of being persuaded without\neven knowing that you're thinking."}]},{"cues":[{"time":940440,"text":"TH: Exactly. The reason\nI care about this problem so much is"},{"time":943320,"text":"I studied at a lab called\nthe Persuasive Technology Lab at Stanford"},{"time":946520,"text":"that taught [students how to recognize]\nexactly these techniques."},{"time":949106,"text":"There's conferences and workshops\nthat teach people all these covert ways"},{"time":952120,"text":"of getting people's attention\nand orchestrating people's lives."},{"time":955120,"text":"And it's because most people\ndon't know that that exists"},{"time":957800,"text":"that this conversation is so important."}]},{"cues":[{"time":959720,"text":"CA: Tristan, you and I, we both know\nso many people from all these companies."},{"time":963520,"text":"There are actually many here in the room,"},{"time":965520,"text":"and I don't know about you,\nbut my experience of them"},{"time":968021,"text":"is that there is\nno shortage of good intent."},{"time":970120,"text":"People want a better world."},{"time":972320,"text":"They are actually -- they really want it."},{"time":976320,"text":"And I don't think anything you're saying\nis that these are evil people."},{"time":980520,"text":"It's a system where there's\nthese unintended consequences"},{"time":984240,"text":"that have really got out of control --"}]},{"cues":[{"time":986120,"text":"TH: Of this race for attention."},{"time":987640,"text":"It's the classic race to the bottom\nwhen you have to get attention,"},{"time":990840,"text":"and it's so tense."},{"time":992080,"text":"The only way to get more\nis to go lower on the brain stem,"},{"time":994840,"text":"to go lower into outrage,\nto go lower into emotion,"},{"time":997280,"text":"to go lower into the lizard brain."}]},{"cues":[{"time":999000,"text":"CA: Well, thank you so much for helping us\nall get a little bit wiser about this."}]},{"cues":[{"time":1002840,"text":"Tristan Harris, thank you.\nTH: Thank you very much."}]},{"cues":[{"time":1005280,"text":"(Applause)"}]}]}